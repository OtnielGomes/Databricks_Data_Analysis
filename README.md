# Databricks Data Analysis API Pandas x PySpark SQL

Hello, in this project we will perform data analysis using two specific tools.

The first tool will be the Pandas API in PySpark, this tool aims to reduce the learning curve for people who used the Pandas library in Python to perform data analysis and processing.

The second tool will be PySpark SQL, in this project we will replicate all the analyzes and visualizations made with the Pandas API.

The objective of this project is to compare the two tools, and check which one has the best solution for each problem, as they are two tools with fun functions and specific characteristics, it was necessary to make some adaptations to be able to replicate all the analyzes and data processing carried out by each tool.

My conclusion is that each tool has its own particularity,
I understand that in a way it is interesting to have knowledge of both in order to fully explore the visualizations and analyzes of a project.

# The Database:

### Note: I recommend using the Databricks tool for a better visualization of the data and the project.

## üöÄ Starting

At the link below you can obtain a copy of the project:
* [copy of the project](https://codeload.github.com/OtnielGomes/My_learning_Databricks_Files_Types/zip/refs/heads/main)

## üõ†Ô∏è Built with:
* [Databricks-Community](https://community.cloud.databricks.com/)
* [Spark-3.5.0-bin-hadoop3.tgz](https://www.apache.org/dyn/closer.lua/spark/spark-3.5.0/spark-3.5.0-bin-hadoop3.tgz)
## üì¶ Frameworks  

* PySpark.SQL
* Apache Spark
* Apache Hive

## ‚öôÔ∏è Running the code:

### Start with the Notebook:
* [My_learning_Databricks_Files_Types](https://github.com/OtnielGomes/My_learning_Databricks_Files_Types/blob/main/Databrick_Types_Files/My_Learning_Databricks_File-Formats.ipynb)


